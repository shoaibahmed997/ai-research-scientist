{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import ctransformers\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import chroma, faiss\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import GrobidParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other imports\n",
    "from utils import show_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "MODEL_PATH = '/Users/shoaib/Downloads/zephyr/zephyr-7b-alpha.Q8_0.gguf'\n",
    "MODEL_FOLDER = '/Users/shoaib/Downloads/zephyr'\n",
    "RESEARCH_PAPERS_FOLDER ='/Users/shoaib/Desktop/deep learning/research papers/'\n",
    "FAISS_STORE_PATH = './vector store/'\n",
    "CHROMA_STORE_PATH = './chroma store/'\n",
    "n_gpu_layers = 1  # Metal set to 1 is enough.\n",
    "n_batch = 512 \n",
    "config = {\"max_new_tokens\":4096,\"context_length\":4096}\n",
    "\n",
    "# for root, dir,files in os.walk(MODEL_FOLDER):\n",
    "    # print(files)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model():\n",
    "    # callback = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    model = ctransformers.CTransformers(\n",
    "        model=MODEL_PATH,\n",
    "        model_type='mistral',\n",
    "        n_gpu_layers=n_gpu_layers,\n",
    "        n_batch=n_batch,\n",
    "        config=config\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "# llm = load_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# document loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load documents\n",
    "# docs_loader = DirectoryLoader(RESEARCH_PAPERS_FOLDER, show_progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:39<00:00,  1.28s/it]\n"
     ]
    }
   ],
   "source": [
    "# docs = docs_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grobid starts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(\n",
    "    './input paper/',\n",
    "    glob=\"*\",\n",
    "    suffixes=[\".pdf\"],\n",
    "    parser=GrobidParser(segment_sentences=False),\n",
    "    show_progress=True,\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# grobid ends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713506\n"
     ]
    }
   ],
   "source": [
    "total_content_len = 0\n",
    "for i in docs:\n",
    "    total_content_len += len(i.page_content)\n",
    "print(total_content_len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# text splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, chunk_overlap=200, add_start_index=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_splits = txt_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no of splits: 2368\n",
      "words in 1st split: 336\n",
      "preview of 1st split: 5 1 0 2\n",
      "\n",
      "r p A 0 1\n",
      "\n",
      "]\n",
      "\n",
      "V C . s c [\n",
      "\n",
      "6 v 6 5 5 1 . 9 0 4 1 : v i X r a\n",
      "\n",
      "Published as a conference paper at ICLR 2015\n",
      "\n",
      "VERY DEEP CONVOLUTIONAL NETWORKS FOR LARGE-SCALE IMAGE RECOGNITION\n",
      "\n",
      "Karen Simonyan∗ & Andrew Zisserman+ Visual Geometry Group, Department of Engineering Science, University of Oxford {karen,az}@robots.ox.ac.uk\n",
      "\n",
      "ABSTRACT\n"
     ]
    }
   ],
   "source": [
    "print(\"total no of splits:\",len(all_splits))\n",
    "print(\"words in 1st split:\",len(all_splits[0].page_content))\n",
    "print(\"preview of 1st split:\",all_splits[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = HuggingFaceEmbeddings(model_name='intfloat/e5-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vector_store = chroma.Chroma.from_documents(documents=all_splits,embedding=embeddings,persist_directory=VECTOR_STORE_PATH)\n",
    "vector_store = faiss.FAISS.from_documents(documents=all_splits,embedding=embeddings)\n",
    "vector_store.save_local(VECTOR_STORE_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 6})\n",
    "retrieved_docs = retriever.invoke(\"What is a gan architecture?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Because of its nature with set-level supervision, the problem can be naturally formulated using the framework of GANs which learns the embedding of the input samples and generates output samples locating within the subspace spanned by training samples. A GAN model often consists of a discriminator D and a generator G. The framework has been used for addressing the image-to-image translation problem which transforms an input image from the source domain X to the output image in the target domain Y [13].\n",
      "\n",
      "6307\n",
      "\n",
      "DY, D'Y\n",
      "\n",
      "DY, D'Y\n",
      "\n",
      "DX, D'X\n",
      "\n",
      "DY\n",
      "\n",
      "DY\n",
      "\n",
      "DX\n",
      "\n",
      "Y'\n",
      "\n",
      "Y\n",
      "\n",
      "X\n",
      "\n",
      "Y'\n",
      "\n",
      "Y\n",
      "\n",
      "y t + n e d\n",
      "\n",
      "GX\n",
      "\n",
      "GX\n",
      "\n",
      "X\n",
      "\n",
      "G'Y\n",
      "\n",
      "X''\n",
      "\n",
      "G'X\n",
      "\n",
      "Y''\n",
      "\n",
      "I\n",
      "\n",
      "X\n",
      "\n",
      "consistency\n",
      "\n",
      "consistency\n",
      "\n",
      "(a) 1-way GAN\n",
      "\n",
      "(b) 2-way GAN\n",
      "\n",
      "Figure 1. The network architectures of 1-way and 2-way GANs.\n",
      "\n",
      "In our application, the source domain X represents original images while the target domain Y contains images with the desired characteristics.\n"
     ]
    }
   ],
   "source": [
    "len(retrieved_docs)\n",
    "print(retrieved_docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
