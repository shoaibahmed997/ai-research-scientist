{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import GrobidParser\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESEARCH_PAPERS_FOLDER ='/Users/shoaib/Desktop/deep learning/research papers/'\n",
    "papers = []\n",
    "for (rooot, _, files) in os.walk('./input paper'):\n",
    "    for file in files:\n",
    "        # print(rooot+file)\n",
    "        papers.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1bitnet llm'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_name = papers[0][:-4]\n",
    "paper_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = GenericLoader.from_filesystem(\n",
    "    './input paper/',\n",
    "    glob=\"*\",\n",
    "    suffixes=[\".pdf\"],\n",
    "    parser=GrobidParser(segment_sentences=False),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'In recent years, the field of AI has seen a rapid growth in the size and capabilities of Large Language Models (LLMs).These models have demonstrated remarkable performance in a wide range of natural language processing tasks, but their increasing size has posed challenges for deployment and raised concerns about their environmental and economic impact due to high energy consumption.One approach to address these challenges is to use post-training quantization to create low-bit models for inference [XLS + 23, FAHA23, CCKS23, TCS + 24].This technique reduces the precision of weights and activations, significantly reducing the memory and computational requirements of LLMs.The trend has been to move from 16 bits to lower bits, such as 4-bit variants [FAHA23, LTT + 23].However, post-training quantization is sub-optimal, even though it is widely used in industry LLMs.',\n",
       " 'para': '5',\n",
       " 'bboxes': \"[[{'page': '2', 'x': '108.00', 'y': '98.87', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '109.78', 'h': '64.90', 'w': '8.64'}], [{'page': '2', 'x': '175.90', 'y': '109.78', 'h': '328.10', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '120.69', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '131.60', 'h': '374.28', 'w': '8.64'}], [{'page': '2', 'x': '487.07', 'y': '131.60', 'h': '16.93', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '142.51', 'h': '396.00', 'w': '8.64'}, {'page': '2', 'x': '108.00', 'y': '153.41', 'h': '78.70', 'w': '8.64'}, {'page': '2', 'x': '186.70', 'y': '151.52', 'h': '6.12', 'w': '6.12'}, {'page': '2', 'x': '193.31', 'y': '153.41', 'h': '118.45', 'w': '8.64'}, {'page': '2', 'x': '311.76', 'y': '151.52', 'h': '6.12', 'w': '6.12'}, {'page': '2', 'x': '318.38', 'y': '153.41', 'h': '15.89', 'w': '8.64'}], [{'page': '2', 'x': '340.15', 'y': '153.41', 'h': '163.85', 'w': '8.64'}, {'page': '2', 'x': '107.64', 'y': '164.32', 'h': '398.10', 'w': '8.64'}], [{'page': '2', 'x': '107.69', 'y': '175.23', 'h': '375.55', 'w': '8.64'}, {'page': '2', 'x': '483.24', 'y': '173.34', 'h': '6.12', 'w': '6.12'}, {'page': '2', 'x': '489.86', 'y': '175.23', 'h': '15.89', 'w': '8.64'}], [{'page': '2', 'x': '108.00', 'y': '186.14', 'h': '397.60', 'w': '8.64'}]]\",\n",
       " 'pages': \"('2', '2')\",\n",
       " 'section_title': 'The Era of 1-bit LLMs',\n",
       " 'section_number': '1',\n",
       " 'paper_title': 'The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits',\n",
       " 'file_path': 'input paper/1bitnet llm.pdf'}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_content = \"\"\n",
    "for i in docs:\n",
    "    paper_content+=(i.page_content)\n",
    "\n",
    "with open(f'./paper content/{paper_name}.txt', 'w+') as f:\n",
    "    f.write(paper_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
